[
{
	"uri": "http://localhost:1313/",
	"title": "Intelligent Document Processing with AWS AI Services",
	"tags": [],
	"description": "",
	"content": "Intelligent Document Processing with AWS AI Services Overview Documents contain valuable information and come in various shapes and forms. In most cases, you manually process these documents to extract information and insights. This is time consuming, error prone, expensive, and difficult to scale. Not only do you want information extracted from your documents quickly, but you also want to automate business processes that presently rely on manual inputs and intervention across various file types and formats.\nTarget of the Workshop The goal of this workshop is to give you hands on experience in understanding and building the components required to setup an IDP workflow with AWS AI services. You will learn how to implement the various stages of an IDP workflow by:\nUsing Amazon SageMaker Studio as an IDE Learning the basics of Amazon Textract and the various APIs that can be used to extract text and derive relationships from document content. Training an Amazon Comprehend custom classifier and use it to classify documents. Training an Amazon Comprehend custom entity recognizer and use it to detect business specific entities. Performing document enrichment using custom entities and document redaction using geometry data generated by Amazon Textract. Learning how Amazon Augmented AI human review loops can be configured for review of extracted information. Cost of the Workshop You can use the functions and AWS services you need immediately in this workshop and test them free of charge in a new AWS account. If you\u0026rsquo;re using an existing AWS account, please refer to the pricing guides for the services listed below for more information.\nAfter the Workshop If you no longer use the implemented functions after the workshop, you may still incur costs. You can find more information about this and how to delete created components in the Clean up\nContent Introduction Preparation Document Classification Manage session logs Port Forwarding DocumentReviewandVerification Clean up "
},
{
	"uri": "http://localhost:1313/6-documentreviewandverification/6.1/",
	"title": "Amazon S3 bucket setup and requirements",
	"tags": [],
	"description": "",
	"content": " We will need an Amazon S3 bucket, which will be used to store data for A2I workers. This is already created as part of the CloudFormation stack. The name of the S3 bucket should be of the pattern idp-a2i-xxxxxxxx. Navigate to the Amazon S3 console to find the bucket name. Go to S3 Setup an A2I Human review workflow Go to the Amazon SageMaker console and click the Human review workflow option under Augmented AI in the left panel. Then click the Create human review workflow button. Provide a Name for the human review workflow. The S3 bucket value must be of the pattern s3://idp-a2i-xxxxxx/. In IAM Role, select Create a new role and then enter the name of the S3 bucket (without s3://, such as idp-a2i-xxxxxx). Under Task type, select Textract - Key-value pair extraction option. Next, under Amazon Textract form extraction - Conditions for invoking human review, select the Trigger human review for all form keys identified by Amazon Textract with confidence scores in a specified range checkbox and enter the values shown below. You can also customize worker task templates but for the purpose of this demo select Create from a default template and enter a Template name (example: idp-a2i-template). Under Worker task template design enter the Task description. You can also customize the Instructions as shown below. Under Workers section, select the Private worker type. Click on the create a new team link to create a new Private Team. Under Add workers, select Invite new workers by email. In the Email addresses section enter your email. Under organization name enter your company name. For Contact Email use your email to receive instructions. Leave the other fields as default and click Create Private Team. Back to Create Human flow and refresh: Click Create to complete creation of the Human review workflow. Once created, the workflow should be active and ready to use. "
},
{
	"uri": "http://localhost:1313/3-documentclassification/3.1-getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "In the first notebook, we will upload these bank statements, invoices, and receipts into an Amazon S3 bucket, use Amazon Textract to extract the raw text from the documents, label the data appropriately, and then train an Amazon Comprehend custom classifier with the labeled data.\nOpen the first notebook titled 01-idp-prep-document-classification.ipynb. You\u0026rsquo;ll be prompted to select an image and kernel. Select the options as shown in the image below and click Select . The notebook should autmatically attach to an ml.t3.medium instance (with 2vCPU and 4GiB memory). If it is not, click on the \u0026ldquo;Switch instance type\u0026rdquo; and select ml.t3.medium from the list of instance. ⚠️ ml.t3.medium is the preferred instance type. Please DO NOT select any other instance type as it may cause the account to incur unexpected charges.\n"
},
{
	"uri": "http://localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Overview The architecture diagram below shows the stages of an Intelligent Document Processing workflow. It starts with a data capture stage to securely store, aggregate different types (pdf, jpeg, png, tiff), formats, and layouts of documents. The next stage is classification, this is where you categorize your documents (for example categories such as contracts, claim forms, invoices, receipts and so on) followed by document extraction. In the extraction stage, you can extract meaningful business information from your documents. This extracted data is often used to gather insights via data analysis, or sent to downstream systems such as databases or transactional systems. The following stage is enrichment, at this stage documents can be enriched by redacting PII data, custom business term extraction, and so on. Finally, in the review/verification stage you can include a human workforce for document reviews to ensure the outcome is accurate. Before we begin Let\u0026rsquo;s look at a brief overview of Amazon Textract, Amazon Comprehend, and Amazon Augmented AI (A2). These are the AWS AI services that will be used in this workshop.\nAmazon Textract Amazon Textract is a machine learning service that automatically extracts text, handwriting, and data from scanned documents. It goes beyond simple optical character recognition (OCR) to identify, understand, and extract data from forms and tables. Today, many companies manually extract data from scanned documents such as PDFs, images, tables, and forms, or through simple OCR software that requires manual configuration (which often must be updated when the form changes). To overcome these manual and expensive processes, Textract uses ML to read and process any type of document, accurately extracting text, handwriting, tables, and other data with no manual effort. You can quickly automate document processing and act on the information extracted, whether you’re automating loans processing or extracting information from invoices and receipts. Textract can extract the data in minutes instead of hours or days. Additionally, you can add human reviews with Amazon Augmented AI to provide oversight of your models and check sensitive data.\nAmazon Comprehend Amazon Comprehend is a natural-language processing (NLP) service that uses machine learning to uncover information in unstructured data. The service can identify critical elements in data, including references to language, people, places, and the text files can be categorized by relevant topics. You can automatically and accurately detect human sentiment from content generated by your users (such as product reviews, social media posts etc.), in real-time. This accelerates more informed decision making to improve customer experiences. Amazon Comprehend not only locates any content that contains personally identifiable information, it can also redact and masks that content. Comprehend is fully managed, so you can get up and running quickly to start processing millions of documents in minutes by leveraging the power of machine learning.\nAmazon Augmented AI (A2I) Amazon Augmented AI is a machine learning service which makes it easy to build the workflows required for human review. Amazon A2I brings human review to all developers, removing the undifferentiated heavy lifting associated with building human review systems or managing large numbers of human reviewers whether it runs on AWS or not. Amazon A2I integrates both with Amazon Textract and Amazon Comprehend to provide you the ability to introduce human review steps within your intelligent document processing workflow.\n"
},
{
	"uri": "http://localhost:1313/3-documentclassification/step-1/",
	"title": "Setup notebook and upload sample documents to Amazon S3",
	"tags": [],
	"description": "",
	"content": "In this step we will install the required librarues, import the required modules, and initialize variables. We will also download the sample documents from our workshop repository and upload them to the SageMaker S3 bucket so we can process them. The curl command below downloads the classification-training.zip file which contains the data that will be required to train our custom Amazon Comprehend Classifier.\nRun from Step 1 to 6 In the subsequenct code cells, we unzip and extract all the files from the zip file and subsequently upload them to an Amazon S3 bucket. Complete executing all the code cells in this step. The data has been put into S3 and can be found in AWS S3. or we can use the code in the file to extract the data "
},
{
	"uri": "http://localhost:1313/3-documentclassification/step-2/",
	"title": "Extract text from sample documents using Amazon Textract",
	"tags": [],
	"description": "",
	"content": "In this section we use Amazon Textract\u0026rsquo;s detect_document_text API to extract the raw text information for all the documents in S3. We will also label the data according to the document type. This labeled data will be used to train a custom Amazon Comprehend classifier. We define a utility function that uses the textract_extract_text API to extract text from a document and find which category (or directory in S3) it belongs to and then label the data and return an array [\u0026lt;label\u0026gt;, \u0026lt;document_text\u0026gt;]. Execute all the code cells in this step to prepare labeled data for Comprehend classifier training. At the end of this step, we should have a collection labeled_collection ready with labeled data required for Amazon Comprehend classification. Note that a large assumption here is that we already have a lebeled set of historic documents to be able to train a custom classification model. "
},
{
	"uri": "http://localhost:1313/2-prerequiste/",
	"title": "Preparation ",
	"tags": [],
	"description": "",
	"content": "\rYou need to create 1 AWS account to perform this lab.\nIf you don\u0026rsquo;t already have an AWS account with Administrator access create one now .\nCreate AWS account Deloy CloudFormation Stack Download the AWS CloudFormation templates using the \u0026ldquo;Download Template\u0026rdquo; button below and use it in the AWS Cloudformation console It cotains a sample of SageMaker Download Template. Search the \u0026ldquo;Cloud Formation\u0026rdquo; Create \u0026ldquo;stack\u0026rdquo; and select \u0026ldquo;With new resources(standard) In prepare template, we choose \u0026ldquo;Choose an existing template\u0026rdquo;, Specify template we choose \u0026ldquo;Upload a template file\u0026rdquo; And \u0026ldquo;Next\u0026rdquo;\nStack name is \u0026ldquo;IDPSageMakerCfnStack\u0026rdquo;, Parameters is default And \u0026ldquo;Next\u0026rdquo;\nNext to Step 4: Review and Create Wait to excute and we get this. Once the CloudFormation stacks are deployed, follow the instructions below to access Amazon SageMaker Studio IDE Amazon SageMaker Studio access Search the \u0026ldquo;SageMaker\u0026rdquo; You should already be in the Domains page, if not click on the Domains option in the left menu. Next, click on the Domain name. Note: if you changed the name of your domain in the cloudformation template then that name will be shown in the list. In the Domain details page click on the Launch drop-down and then click on Studio The SageMaker Studio IDE will open in a new browser tab. The page may take a few minutes to load when you access SageMaker Studio for the first time. Once the SageMaker Studio IDE loads, you will be presented with the UI with a screen that looks like this. Click on \u0026ldquo;Studio Classic\u0026rdquo; (on the left menu near the top). You will see an existing SageMaker Studio classic application running. Click on \u0026ldquo;Open\u0026rdquo;. You will be redirected to a new browser tab with the Amazon SageMaker Studio Classic IDE: Once you are in the Amazon SageMaker Studio IDE, you should already see the workshop repo folder. "
},
{
	"uri": "http://localhost:1313/6-documentreviewandverification/6.2/",
	"title": "Verification",
	"tags": [],
	"description": "",
	"content": "Now let\u0026rsquo;s go back to the notebook 04-idp-document-a2i.ipynb. Start running the code cells from the beginning. You will need to provide few details as you move along.\nEnter the S3 bucket name idp-a2i-xxxxxx to initialize the BUCKET variable. We will use this BUCKET variable throughout the notebook. You would need to provide the private work team ARN that you had created before. To find the work team ARN, click the Human review workflow you created earlier and copy the ARN from the Summary section under Workforce. It should look like \u0026lt;arn:aws:sagemaker:\u0026lt;region\u0026gt;:\u0026lt;account_id\u0026gt;:workteam/private-crowd/\u0026lt;team-name\u0026gt;. Enter this value to initialize the WORKTEAM_ARN in the notebook. Now that we have setup the A2I WorkFlow definition, all that\u0026rsquo;s left is calling Amazon Textract\u0026rsquo;s Analyze Document API including the A2I paramters in the HumanLoopConfig. Provide the A2I workflow ARN to be used by Amazon Textract. You can find the workflow ARN in the Human review workforce Summary screen. Execute the code cell to perform AnalyzeDocument. Once data is extracted using Amazon Textract, the key-value pairs show up in the labeling portal for human review. Then go to Amazon SageMaKer -\u0026gt; Labeling workforces Click to Labeling portal sign-in URL Login to the labelling/human review portal. You should have received an email with a link to the Labeling/human review portal with details about how to login and a portal URL. Follow the instructions in the email, you will need to reset your password to login. You can see that a human review task has been added. Select the job and click on Start Working. You can now get to see the extracted information on the right, in order to verify and make changes if needed. Submit the job once completed. You also have the option to decline and release the task if needed. Conclusion In this notebook we created an A2I human review workflow for Amazon Textract including a private work team using Amazon Augmented AI. We then used Amazon Textract to extract data from a sample document and added a Human Config Loop for Human Review. Finally, we performed a manual review task using a customized portal.\n"
},
{
	"uri": "http://localhost:1313/3-documentclassification/",
	"title": "Document Classification",
	"tags": [],
	"description": "",
	"content": "Overview Document classification is a two-step process. First, you train a custom classifier to recognize the classes that are of interest to you. Then you send unlabeled documents to be classified.\nTo train the classifier, specify the options you want, and send Amazon Comprehend documents to be used as training material. Based on the options you indicated, Amazon Comprehend creates a custom ML model that it trains based on the documents you provided. This custom model (the classifier) examines each document you submit. It then returns either the specific class that best represents the content (if you\u0026rsquo;re using multi-class mode) or the set of classes that apply to it (if you\u0026rsquo;re using multi-label mode).\nIn this lab we will walk you through a hands-on lab on document classification using Amazon Comprehend Custom Classification . We will use Amazon Textract to first extract text from our documents, label them, and then use the data for training our Amazon comprehend custom classifier. Our goal is - given a group of unknown documents, we want to be able to categorize which documents are bank statements, which are invoices, and which are receipts. To prepare the training data, we will use pre-existing bank statements, receipts, and invoices.\nSample Document Corpus Bank Statements The image below is the first page of a standard multi-page bank statement with details such as Customer Name, Address, Account Summary, Current balance, etc. Invoices The image below is a standard payment invoice with details such as Business Details, Bill to, products, invoice ID etc. Receipts The image below is a standard store reciept with details such as Items purchased, Store Details, Retail price for each Item, Sales Tax Rate, etc. "
},
{
	"uri": "http://localhost:1313/3-documentclassification/step-3/",
	"title": "Prepare a CSV training dataset for Amazon Comprehend custom classifier training",
	"tags": [],
	"description": "",
	"content": "In this step, the extracted data is written into a CSV file and uploaded to S3. This file will be used as training data for next step. We will be training an Amazon Comprehend custom classifier in Multi-class mode using a CSV file. Take a look at the documentation for preparing data for a Multi-class mode model training. The CSV files are UTF-8 encoded plaintext files and should be of format.\nCLASS,Text of document 1\rCLASS,Text of document 2\rCLASS,Text of document 3 Complete executing the code cells in this section to prepare the CSV file and upload it to S3. At the end of this step we will have our training data in CSV format in a file named comprehend_train_data.csv with classes bank-statements, invoices and receipts.\nNow that we have text extracted from our documents and have also labeled them, we will create the training data in order to train an Amazon Comprehend custom classification model. Let\u0026rsquo;s take a look at the labeled data. We have 100 sample of each document, so we should have about 300 rows of labeled data. We will create a training dataset from extracted text and upload it to Amazon S3. The training data file will be written in CSV format and will be named comprehend_train_data.csv. Note that you can have more than one CSV file in an S3 bucket for training a Comprehend custom classifier. If you have more than one file, you can specify only the bucket/prefix in call to train the custom classifier. Amazon Comprehend will automatically use all the files under the bucket/prefix for training purposes.\nThe following code cells will upload the training data to the S3 bucket, and create a Custom Comprehend Classifier. You can also create a custom classifier manually, please see the subsequent sections for instructions on how to do that. Complete executing the code cells in this section to prepare the CSV file and upload it to S3. At the end of this step we will have our training data in CSV format in a file named comprehend_train_data.csv with classes bank-statements, invoices and receipts. "
},
{
	"uri": "http://localhost:1313/3-documentclassification/step-4/",
	"title": "Create Amazon Comprehend Classification training job",
	"tags": [],
	"description": "",
	"content": "Now that we have text extracted from our documents and have also labeled them, we will create the training data in order to train an Amazon Comprehend custom classification model . Our corpus has 100 samples of each document, so we should have about 300 rows of labeled data.\nWe will use Amazon Comprehend\u0026rsquo;s Custom Classification to train our own model for classifying the documents. We use the CreateDocumentClassifier API to create a classifier which will train a custom model using the labeled data CSV file we created above. The training data contains extracted text, that was extracted using Amazon Textract, and then labeled. The following code cell uses create_document_classifier from boto3 Python SDK to initiate the model training process.\nCreate Amazon Comprehend custom classification Training Job We will use Amazon Comprehend\u0026rsquo;s Custom Classification to train our own model for classifying the documents. We will use Amazon Comprehend CreateDocumentClassifier API to create a classifier which will train a custom model using the labeled data CSV file we created above. The training data contains extracted text, that was extracted using Amazon Textract, and then labeled. Note that you can also create a custom classifier using the Amazon Comprehend console manually. Refer to the documentation to learn more how to create a custom classifier using the console. Continue with the remaining of the cells in this step. The custom classifier training could take upto ~30 mins. "
},
{
	"uri": "http://localhost:1313/4-documentextraction/",
	"title": "Document Extraction",
	"tags": [],
	"description": "",
	"content": "Extracting data from documents using Amazon Textract Amazon Textract is a machine learning (ML) service that automatically extracts text, handwriting, and data from scanned documents. It goes beyond simple optical character recognition (OCR) to identify, understand, and extract data from forms and tables. Expand the following sections to take a brief look at the document extraction capabilities of Amazon Textract.\nParsing Amazon Textract API responses You can extract text and structured data information using Amazon Textract\u0026rsquo;s DetectDocumentText and AnalyzeDocument APIs respectively. These APIs respond with JSON data which contains WORDS, LINES, FORMS, TABLES, geometry or bounding box information, relationships and so on. This JSON response can be tricky to parse, especially for larger or multi-page documents. For this purpose, we will use a group of tools named amazon-textract-textractor that makes it easy to obtain information such as WORDS, LINES, TABLES, and FORMS from the document, and obtain bounding box information. Following are the features available\nA caller which provides a collection of ready to use functions and sample implementations to speed up the evaluation and development for any project using Amazon Textract. Making it easy to call Amazon Textract regardless of file type and location. A response parser to easily parse JSON returned by Amazon Textract. The library parses JSON and provides programming language specific constructs to work with different parts of the document. A prettyprinter which provides functions to format the output received from Amazon Textract in more easily consumable formats such as CSV or markdown. An overlayer that gets you bounding box geometry information that can be used for annotation, or redaction purposes. Getting Started with Lab In this part, we will look at ways to extract information from documents. Open the 02-idp-document-extraction.ipynb notebook in Amazon SageMaker Studio and follow the steps below. Step 1: Setup notebook In this step we will select kernel like previous notebook that will be used in the notebook. Then run scripts in Step 1 Let\u0026rsquo;s select a bank statement we classified in the previous exercise Step 2: Extract unstructured data with Amazon Textract In this step we will mainly look at how to extract text information (LINES and WORDS) from one of the bank statements. Text data in the form of WORDS and LINES can be extracted from documents using Amazon Textract DetectDocumentText API. Following code calls the API to extract text from documents.\nAmazon Textract is an ML powered OCR service that is capable of detecting and extracting text from documents. Text data in the form of WORDS and LINES can be extracted from documents using Amazon Textract DetectDocumentText API. Let\u0026rsquo;s extract the words and lines from the bank statement. As you can notice, we were able to extract the LINES and WORDS from the document, but we also lost some of the structural formatting within the document. For example the document contains a few tables and we would like to extract the table information in a tabular structure. So let\u0026rsquo;s do that next.\nStep 3: Extract table data using Amazon Textract In this step we will take a brief look at how to extract table information from the bank statemente. Our bank statement has two tables. As you can see, the response from Amazon Textract is a large JSON object that contains a lot of information. Let\u0026rsquo;s parse out the table data from this reponse. To do this, we will see how to extract the tables using the textract response parser tool that we installed earlier. In the code cells above, we used the Textract AnalyzeDocument API to extract info from the document and subsequently used textract response parser Document to parse out the tables from the JSON response. We can further use additional tooling to call the Textract API and use textract pretty printer tool to view the tables in a slightly more human readable way. We will see how to extract the tables using the Textract pretty printer tool. We will also use call_textract method from the Textract Caller tool that we installed earlier. These set of tools make it easy for us to make Textract API calls and parse it\u0026rsquo;s JSON output. In our subsequent sections, we will make use of these tools to make API calls and subsequently to parse the JSON response. In the code cell above, we extracted the tables as a Python List and then converted them to Pandas DataFrame. You can also extract tables in other formats such as CSV, TSV etc. Refer to the PrettyPrinter documentation for more. Now let\u0026rsquo;s look at the DataFrames. Step 4: Extract forms (key/value) data using Amazon Textract Let\u0026rsquo;s look at how Amazon Textract can be used to extract form data from the document. In this example, we will use a sample Employment Verification form. In our previous example, our document was in S3 and we called Amazon Textract by specifying the S3 location of the document. In this case our document is present locally, we can either upload this document into S3, or we can use the document\u0026rsquo;s Byte Array from our local environment to call the API. Let\u0026rsquo;s use the document Byte Array for this example. Note that this method only applies to Textract Sync (real-time) APIs, since the async APIs only support documents placed in S#. In the code cell below, we first convert our document to a Byte array, and then call the AnalyzeDocument API with FORMS feature. Subsequently we use textract response parser tool to parse out the form key/value pairs and print them out. And the result Step 5: Query based extraction using Amazon Textract When processing a document with Amazon Textract, you may add queries to your analysis to specify what information you need. This involves passing a question, such as \u0026ldquo;What is the customer\u0026rsquo;s social security number?\u0026rdquo; to Amazon Textract. Amazon Textract will then find the information in the document for that question and return it in a response structure separate from the rest of the document\u0026rsquo;s information. Queries can be processed alone, or in combination with any other FeatureType, such as TABLES or FORMS. Queries can be a powerful tool in situations where only a few pieces of critical information is desired from a document.\nLet\u0026rsquo;s pass a couple of Queries to extract from our Employment Verification form. Step 6: Signature detection with Amazon Textract Amazon Textract can detect the presence of signatures in documents. The AnalyzeDocument API has the following four feature types – Forms, Tables, Queries, and Signatures. The Signatures feature can be used by itself or in combination with other feature types. When used by itself, Signatures feature type provides a json response that includes a) location and confidence scores of the detected signatures and b) raw text (words and lines) from the documents. If the Signatures feature is used along with Forms feature that extracts key value pairs in a form, the detected signature will be associated as a value to the relevant key. Similarly, when used along with Tables feature type, the detected signature will be associated to a cell within the table.\nLet\u0026rsquo;s try to detect the signatures in our Employment Verification form. Textract has detected three signatures in the document along with their bounding box information along with the confidence scores.\nStep 7: Extracting invoices/receipts with Amazon Textract Let\u0026rsquo;s now look at the AnalyzeExpense API to extract information from an invoice document. It is important to note that textract provides the ability to seperately extract the \u0026ldquo;line items\u0026rdquo; in the invoice and the \u0026ldquo;Summary\u0026rdquo; of the invoice. Step 8: Extracting identity documents with Amazon Textract To see how extraction of identity documents works with Amazon Textract we will use a sample Passport document. Passport is a special document, i.e. an Identity document. To extract infromation from US passports and driver\u0026rsquo;s license, Amazon Textract\u0026rsquo;s AnalyzeID API can be used. We will use the call_textract_analyzeid tool from the amazon-textract-textractor library. Note that in the call to call_textract_analyzeid you can also pass an S3 path to the parameter document_pages as call_textract_analyzeid(document_pages=[\u0026quot;s3://bucket/prefix/doc.png\u0026quot;])\nLet\u0026rsquo;s look at the extracted information from the Passport document. Notice that the Keys are normalized, this means it makes it easy to parse out the required information from the response JSON from Textract. "
},
{
	"uri": "http://localhost:1313/3-documentclassification/step-5/",
	"title": "Classify documents with Amazon Comprehend custom classifier",
	"tags": [],
	"description": "",
	"content": "In this step we will use Amazon Comprehend custom classification model to classify sample documents. We will use start_document_classification_job API to launch an asynchronous job to classify the documents. This API supports documents in their native format (PDF/PNG/JPG/TIF) and can use Amazon Textract behind the scenes to read the text from the documents and subsequently determine the document class.Let\u0026rsquo;s start by uploading our sample documents to the S3 bucket Amazon Comprehend Async classification works with PDF, PNG, JPEG, as well as UTF-8 encoded plaintext files. Since our sample documents under the samples directory are of PNG format, we will specify a DocumentReadAction and use Amazon Textract with the TEXTRACT_DETECT_DOCUMENT_TEXT option. This will tell Amazon Comprehend to use Amazon Textract DetectDocumentText API behind the scenes to extract the text and then perform classification. For InputFormat, we will use ONE_DOC_PER_FILE mode which signifies that each file is a single document (the other mode is ONE_DOC_PER_LINE which means every line in the plaintext file is a document, this is best suited for small documents such as product reviews or customer service chat transcripts etc.) Check status of the classification job The code block below will check the status of the classification job. If the job completes then it will download the output predictions. The output is a zip file which will contain the inference result for each of the documents being classified. The zip will also contain the output of the Textract operation performed by Amazon Comprehend. Continue run next code Let\u0026rsquo;s take a look at the Amazon Comprehend classification output. We have collected the output for all the files in a documents variable. The script above will download and un-zip the zip file locally, so you can navigate into the classification-output directory from the file browser panel on the left and inspect the files manually. Our documents under the samples/mixedbag folder has now been classified. We will upload them into S3 with proper prefix label. The Comprehend classification process has also generated the Textract output from the documents (present under the classification-output/amazon-textract-output). This directory contains a folder for each document with the Amazon Textract JSON response. Let\u0026rsquo;s load the plain text of each of these documents into the data frame. We use the pretty printer tool to get the LINES out of the documents. Continue to the Lab\n"
},
{
	"uri": "http://localhost:1313/5-documentextractionandenrichment/",
	"title": "Document Extraction and Enrichment",
	"tags": [],
	"description": "",
	"content": " ⚠️ PRE-REQUISITE: In order to execute this notebook, make sure you have completed the first notebook 01-idp-document-classification.ipynb\nOverview So far, in the previous two modules, we have categorized documents and identified the bank statements, invoices, and receipt documents. In this module we will look at Amazon Comprehend\u0026rsquo;s default entities and also train an Amazon Comprehend custom entity recognizer and deploy an endpoint with it. The purpose of the custom entity recognizer is to identify the specific entities and generate custom metadata about our document in CSV format to be later analyzed by the business use case. In adition to this we also want to identify any checking and savings account numbers in the bank statements and perform redactions on them. What is Named Entity Recognition (NER)? Named entity recognition (NER) is a natural language processing (NLP) sub-task that involves sifting through text data to locate noun phrases called named entities and categorizing each with a label, such as person, organization, or brand. For example, in the statement “I recently subscribed to Amazon Prime,” Amazon Prime is the named entity and can be categorized as a brand.\nGetting Started Open the 03-idp-document-enrichment.ipynb notebook and follow the steps below Step 1: Setup notebook In this step, we will import some necessary libraries that will be used throughout this notebook. Step 2: Perform Name Entity Recognition using Amazon Comprehend We have categorized our documents according to their respective document types and stored them in S3. Next, we will perform name entity recognition for 1 bank statement and 1 receipt using Amazon Comprehend NER, in this case Comprehend will extract the prebuilt generic entity types from the documents.\nWe will start the process by loading the extracted document text from S3 into a dataframe and subsequently using Amazon Comprehend DetectEntities API. Execute entity extraction on Bank Statement You can see various entities in the text from the our sample bank statement. Note that these are the default entities that Amazon Comprehend has detected using the default pre-trained entity recognizer. Although entity extraction worked fairly well in identifying the generic entity types for everything in the documents, we want specific entities to be recognized for our use case. More specifically, we need to identify the customer\u0026rsquo;s Savings and Checking bank account numbers, for example we want the entity types to be \u0026ldquo;CHECKING_AC\u0026rdquo; and \u0026ldquo;SAVINGS_AC\u0026rdquo;.\nAmazon Comprehend\u0026rsquo;s default prebuilt entity recognizer isn\u0026rsquo;t aware of these entity types, so we will need to train and use a custom entity recognizer in this notebook. We will also perform some document enrichments for example, in the bank statement we want to redact the customer\u0026rsquo;s account numbers. We will discuss more and do all of this in the next notebook.\nStep 3: Train a custom Amazon Comprehend entity recognizer We will be training a custom Amazon Comprehend entity recognizer. There are two ways a custom recognizer can be trained -\nUsing Annotations Using Entity Lists Annotations uses a large set of PDF files that have been annotated. These annotations can be created with service such as Amazon Ground Truth where real human workers can review your files and annotate them. This method is quite involved and if you are interested to learn more refer to this blog and this blog. In our case, we will use Entity Lists, which is a CSV file that should contain the texts and it\u0026rsquo;s corresponding entity type. The entities in this file is going to be specific to our business needs. For the purposes of this exercise, we have provided an entity list in CSV format in the /entity-training/ directory called entitylist.csv. This file contains a custom entity Type for customer account numbers. We have used CHECKING_AC and SAVINGS_AC as the custom entity types. With this, we ultimately need the custom entity recognizer to recognize the savings and checking bank account numbers.\nLet\u0026rsquo;s take a look at our entity list. Let\u0026rsquo;s train a custom entity recognizer with Amazon Comprehend. In order to train a custom entity recognizer we will need the entity list and the set of documents to train the model. We will use the same set of documents that we used earlier to train the custom classifer for this purpose.\nEach custom entity needs atleast 100 samples in the data corpus (documents) for training purposes, meaning you should have atleast a 100 documents containing examples of each of the custom entities in your training dataset. Also, a minimum of 250 entity matches are needed per entity in the entity list to train a model for custom entity recognition. We have provided a training corpus named entity_training_corpus.csv which can be used to train the entity recognizer along with the entity list. Note that this corpus was generated the same way we generated training data for training a custom classifier in the first notebook. With these two data sets we will use Amazon Comprehend\u0026rsquo;s CreateEntityRecognizer API.\nLet\u0026rsquo;s now train a custom entity recognizer with this data and the entity list of savings and checking account numbers Check status of the Comprehend custom entity recognizer job Step 4: Create custom entity recognizer real-time endpoint We will create a real time entity recognizer endpoint with the trained entity recognizer. Once created, the endpoint can be located in the Amazon Comprehend console. Document Enrichment 1 We now have a custom entity recognizer real-time endpoint using which we can extract the custom entities from one of our bank statement documents. Now instead of returning us generic entities, Amazon Comprehend is returning us the entities from our scanned document that we are interested, i.e. the checking and savings account number. Enrichment 2: Perform redaction document enrichment We still need to perform some enrichments on the document. Since the document contains the customers savings and checking account numbers, we would like to redact those. Since we already know, by means of our custom entity, the savings and checking account number of the customer, we can easily use Amazon Textract\u0026rsquo;s geometry data to redact that information wherever they appear in the document. We will pick a bank statement from our list of documents, we will get the S3 location of the document and then perform the actions below-\nUse Amazon Textract to get the geometry information i.e. the bounding boxes, of all the lines in the document Use the extracted text above to identify the entities CHECKING_AC and SAVINGS_AC, using Comprehend custom entity recognizer Find the bounding box for the CHECKING_AC and SAVINGS_AC words from the Textract response Use the bounding box geometry to annotate the document and redact the customer name and address. The function above finds the custom entities in the document, finds the corresponding geometry information of the custom entity text and perform redaction on the document. Let\u0026rsquo;s call it for a sample bank statement. Once our redacted file has been generated, lets take a look at it\u0026hellip; As you can see, the checking and savings account numbers are hidden in the document now.\nConclusion In this notebook we trained an Amazon Comprehend custom entity recognizer using our own entity list so that we can extract those entities from our documents. We used 2 entities CHECKING_AC, and SAVINGS_AC. We then created an endpoint with the custom entity recognizer and performed a detect_entities with the endpoint with one of the bank statements. Finally, we saved the extracted entities into a CSV file and uploaded it to S3 for further analysis.\nWe still needed to perform some enrichments on the document. Since the document contains the customers checking and savings account numbers, we would like to redact those. Since we already know, by means of our custom entity, the customer\u0026rsquo;s checking and savings bank account numbers, we used Amazon Textract\u0026rsquo;s geometry data to redact that information in the document.\n"
},
{
	"uri": "http://localhost:1313/6-documentreviewandverification/",
	"title": "Document Review and Verification",
	"tags": [],
	"description": "",
	"content": "Overview Amazon Augmented AI (Amazon A2I) makes it easy to build the workflows required for human review of ML predictions. Amazon A2I brings human review to all developers, removing the undifferentiated heavy lifting associated with building human review systems or managing large numbers of human reviewers.\nAmazon A2I provides built-in human review workflows for common machine learning use cases, such as content moderation and text extraction from documents, which allows predictions from Amazon Rekognition and Amazon Textract to be reviewed easily. You can also create your own workflows for ML models built on Amazon SageMaker or any other tools. Using Amazon A2I, you can allow human reviewers to step in when a model is unable to make a high confidence prediction or to audit its predictions on an on-going basis.\nResource required for A2I To incorporate Amazon A2I into your human review workflows, you need three resources. Expand the following sections to learn more about each of the resources.\nWorker task template A worker task template to create a worker UI. The worker UI displays your input data, such as documents or images, and instructions to workers. It also provides interactive tools that the worker uses to complete your tasks.\nHuman review workflow A human review workflow, also referred to as a flow definition. You use the flow definition to configure your human workforce and provide information about how to accomplish the human review task. For built-in task types, you also use the flow definition to identify the conditions under which a review human loop is triggered. For example, with Amazon Textract can analyze text in a document using machine learning. You can use the flow definition to specify that a document will be sent to a human for content moderation review if Amazon Textracts\u0026rsquo;s confidence score output is low for any or all pieces of text returned by Textract. You can create a flow definition in the Amazon Augmented AI console or with the Amazon A2I APIs.\nHuman loop A human loop to start your human review workflow. When you use one of the built-in task types, the corresponding AWS service creates and starts a human loop on your behalf when the conditions specified in your flow definition are met or for each object if no conditions were specified. When a human loop is triggered, human review tasks are sent to the workers as specified in the flow definition.\nWhen using a custom task type, you start a human loop using the Amazon Augmented AI Runtime API. When you call StartHumanLoop in your custom application, a task is sent to human reviewers.\n"
},
{
	"uri": "http://localhost:1313/7-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nGo to notebook 05-idp-cleanup.ipynb and follow the code cells to delete the resources created in the account. Go to Amazon Comprehend console to verify if all endpoints and models are deleted. Go to Amazon S3 console navigate to the bucket named sagemaker-studio and idp-a2i-xxxxxx and verify everything within the buckets have been deleted. Go to CloudForMation and delete "
},
{
	"uri": "http://localhost:1313/3-documentclassification/step-6/",
	"title": "Create Amazon Comprehend real-time endpoint (optional)",
	"tags": [],
	"description": "",
	"content": "To use the Amazon Comprehend custom classifier model we need to create a real-time endpoint. Real time endpoints can either be created programmatically using Comprehend\u0026rsquo;s Boto3 client or manually via the console. To learn how to create a real-time endpoint using console refer to the documentation. We use the CreateEndpoint API via Boto3 comprehend.create_endpoint() method to create the real-time endpoint.\nOnce our Comprehend custom classifier is fully trained (i.e. status = TRAINED). We can create a real-time endpoint. We will use this endpoint to classify documents in real time. The following code cells use the comprehend Boto3 client to create an endpoint, but you can also create one manually via the console. Instructions on how to do that can be found in the subsequent section. It may take ~15 minutes for the endpoint to get created. Once the end-point is created successfully, you can begin classifying documents (these are our unknown set of documents) under the /samples/mixedbag directory. Recall that our goal is to classify these unknown documents into bank statements, invoices and receipts respectively. "
},
{
	"uri": "http://localhost:1313/3-documentclassification/step-7/",
	"title": "Classify a document with the real-time endpoint (optional)",
	"tags": [],
	"description": "",
	"content": "The next step is to use the Amazon Comprehend real-time endpoint to classify these documents. We use the comprehend.classify_document()function with extracted document text and inference endpoint as input parameters. To classify a sample document, we will first convert the document to ByteArray and then use Textract classify_document API to classify it. Since classify_document is a real time (synchronous) API we will call it with the document bytes of the above sample document. Again, as before we will let Amazon Comprehend utilize Amazon Textract behind the scenes to read the document and then classify it. Since we are allowing Comprehend to use Amazon Textract behind the scenes to extract the text, we will be limited to use single page documents.\nOnce the endpoint has been created, we will use a mix of documents under the /samples/mixedbag/ directory and try to classify them to bank statement, invoice, and receipt documents respectively. Let\u0026rsquo;s view one of the documents To classify this sample document, we will first convert the documents to ByteArray and then use Textract classify_document API to classify it. Since classify_document is a real time (synchronous) API we will call it with the document bytes of the above sample document. Again, as before we will let Amazon Comprehend utilize Amazon Textract behind the scenes to read the document and then classify it. Since we are allowing Comprehend to use Amazon Textract behind the scenes to extract the text, we will be limited to use single page documents. Lets now run the inference on our sample document Note that Comprehend will return all the classes of documents with a confidence score linked to each class in an array of key-value pairs (Name-Score), we can pick only the document class with the highest confidence score from the endpoint\u0026rsquo;s response.\nConclusion In this notebook we have trained an Amazon Comprehend custom classifier using our sample documents by extracting the text from the documents using Amazon Textract and labeling the data into a CSV file format training dataset. We then trained an Amazon Comprehend custom classifier with the extracted text and created an Amazon Comprehend Classifier real time endpoint to perform classification of a set of unknown documents.\nIn the next notebook we will look at a few methods to perfrom extraction of key insights from our documents using Amazon Textract.\n"
},
{
	"uri": "http://localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]